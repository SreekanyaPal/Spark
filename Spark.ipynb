{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59184f4e-29e7-42c0-9c37-bfd45878249e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\sreek\\anaconda3\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e05414f-e606-4e5b-a522-44e573db7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d7a6dd3-8c79-421f-a2ce-6bf84ecdccdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sree</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>som</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nazlee</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  age\n",
       "0    sree   21\n",
       "1     som   34\n",
       "2  nazlee   55"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8bada13-c4f2-4ce7-a9b5-11c46ef8d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15186db5-09f5-4dab-9719-1fa878db54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b5cb67-962f-4f92-983a-50eee075fba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-I1UD8IKQ:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x24cdb9408f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a062de55-f9ea-44f9-b488-b080e1326c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7791df3-6bdf-4e21-8a57-5e16ee5e1307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f7b8f8d-8a81-4dc4-a896-a9b5b8bff8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|   _c0|_c1|\n",
      "+------+---+\n",
      "|  name|age|\n",
      "|  sree| 21|\n",
      "|   som| 34|\n",
      "|nazlee| 55|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79c58f68-1beb-4e6e-bf41-c3793aab7cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "335976b3-9ec9-4e8d-a61a-183f8260b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "|  sree| 21|\n",
      "|   som| 34|\n",
      "|nazlee| 55|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('Book1.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eed31e09-610a-4b2b-a556-0c7aed72a1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69ab6228-d43a-428a-80bc-24cad602ca82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='name', _c1='age'),\n",
       " Row(_c0='sree', _c1='21'),\n",
       " Row(_c0='som', _c1='34')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5568f00-72ea-4bc0-9db8-d73870f26ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86ea7a2d-7591-44ee-975a-4869b5e9f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36d8b28c-5e47-4ce5-98c5-9b661afcbab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f848f302-81b8-42de-b7a0-1812c3074204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-I1UD8IKQ:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x24cdb9408f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5efe4fd4-8704-454b-8c52-2a5f9b31ea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, age: int, experience: int]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##read the dataset\n",
    "spark.read.option('header','true').csv('book2.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "841a53b9-5d63-4260-bae4-4b56e32efd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|age|experience|\n",
      "+------+---+----------+\n",
      "|  sree| 20|         1|\n",
      "|   som| 21|         2|\n",
      "|nazlee| 23|         3|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('book2.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c26ebf2b-d882-4a6f-80e8-07b4fdd4ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()   ##checking the datatypes of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "329a4e4b-08f4-430d-add4-c96bd850c586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1822902a-398c-4720-b11b-e966e0c106ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'age', 'experience']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24daf0f3-40a1-45d3-bcc9-9c96c0f0d5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='sree', age=20, experience=1),\n",
       " Row(Name='som', age=21, experience=2),\n",
       " Row(Name='nazlee', age=23, experience=3)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82ecba87-bad5-4d16-8233-b00579902e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|  Name|Experience|\n",
      "+------+----------+\n",
      "|  sree|         1|\n",
      "|   som|         2|\n",
      "|nazlee|         3|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2ddafbd5-52fa-4c46-aedd-43489b916ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('age', 'int'), ('experience', 'int')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "370ded82-084d-4995-b2d6-28f15dd87b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+----------+\n",
      "|summary|  Name|               age|experience|\n",
      "+-------+------+------------------+----------+\n",
      "|  count|     3|                 3|         3|\n",
      "|   mean|  NULL|21.333333333333332|       2.0|\n",
      "| stddev|  NULL|1.5275252316519465|       1.0|\n",
      "|    min|nazlee|                20|         1|\n",
      "|    max|  sree|                23|         3|\n",
      "+-------+------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4dfc01ef-c36c-4dee-abc3-808312ce024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, age: int, experience: int, Experience after 2 yaer: int]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add colunm in dataframe\n",
    "df_pyspark.withColumn('Experience after 2 yaer',df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "12c84ab2-a8d6-485a-9667-b4a2b478c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+-----------------------+\n",
      "|  Name|age|experience|Experience after 2 yaer|\n",
      "+------+---+----------+-----------------------+\n",
      "|  sree| 20|         1|                      3|\n",
      "|   som| 21|         2|                      4|\n",
      "|nazlee| 23|         3|                      5|\n",
      "+------+---+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumn('Experience after 2 yaer',df_pyspark['Experience']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7050645c-5eca-4a13-bc6b-4855b19ff8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, age: int, experience: int]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.drop('Experience after 2 yaer')   ##drop a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e832b1a2-7d33-4e89-979e-7e77399fe185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|age|experience|\n",
      "+------+---+----------+\n",
      "|  sree| 20|         1|\n",
      "|   som| 21|         2|\n",
      "|nazlee| 23|         3|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "202a7f6d-813b-4a91-b615-5739b630b512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[New Name: string, age: int, experience: int]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reaname of column\n",
    "df_pyspark.withColumnRenamed('Name','New Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc8bb78a-b08b-4ef5-af85-88a4e6a57a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|age|experience|\n",
      "+------+---+----------+\n",
      "|  sree| 20|         1|\n",
      "|   som| 21|         2|\n",
      "|nazlee| 23|         3|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "07ae9047-b429-450c-8cd5-919d9aa81bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a17d33ed-4e73-4394-a56e-9686a103c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "99458853-2c95-4017-b767-b5471bbc7a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('book3.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "559acbd6-ea3b-46f3-9887-f68ff1b8af2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| name| age|experience|salary|\n",
      "+-----+----+----------+------+\n",
      "|  ram|  33|        12|  3000|\n",
      "|shyam|  43|        34|  7000|\n",
      "| jodu|  45|        56|  6000|\n",
      "|modhu|  65|        22|  8000|\n",
      "| hari|  77|         1|  9000|\n",
      "| mira|  56|        23| 10000|\n",
      "| valu|NULL|      NULL|  9030|\n",
      "| NULL|  45|         5| 67000|\n",
      "| NULL|  67|      NULL|  NULL|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8e6354dc-59e1-414d-ab8d-0ba97804c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|experience|salary|\n",
      "+----+----------+------+\n",
      "|  33|        12|  3000|\n",
      "|  43|        34|  7000|\n",
      "|  45|        56|  6000|\n",
      "|  65|        22|  8000|\n",
      "|  77|         1|  9000|\n",
      "|  56|        23| 10000|\n",
      "|NULL|      NULL|  9030|\n",
      "|  45|         5| 67000|\n",
      "|  67|      NULL|  NULL|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "18e68b65-45df-4ba8-ad3a-cad647449888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| name| age|experience|salary|\n",
      "+-----+----+----------+------+\n",
      "|  ram|  33|        12|  3000|\n",
      "|shyam|  43|        34|  7000|\n",
      "| jodu|  45|        56|  6000|\n",
      "|modhu|  65|        22|  8000|\n",
      "| hari|  77|         1|  9000|\n",
      "| mira|  56|        23| 10000|\n",
      "| valu|NULL|      NULL|  9030|\n",
      "| NULL|  45|         5| 67000|\n",
      "| NULL|  67|      NULL|  NULL|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dd397c5f-5245-42d3-a703-b1ee5e28c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| name|age|experience|salary|\n",
      "+-----+---+----------+------+\n",
      "|  ram| 33|        12|  3000|\n",
      "|shyam| 43|        34|  7000|\n",
      "| jodu| 45|        56|  6000|\n",
      "|modhu| 65|        22|  8000|\n",
      "| hari| 77|         1|  9000|\n",
      "| mira| 56|        23| 10000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show() ##removing the null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7356d11-fdb1-4cc7-a04b-299f57700582",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'how' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### any == how\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_pyspark\u001b[38;5;241m.\u001b[39mna\u001b[38;5;241m.\u001b[39mdrop(how\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow\n",
      "\u001b[1;31mNameError\u001b[0m: name 'how' is not defined"
     ]
    }
   ],
   "source": [
    "### any == how\n",
    "df_pyspark.na.drop(how==\"all\").show ## how is bydefalut any,means there are some null value ,it only remove that \n",
    "value,all means all value will be removesd but there is even one null value so it may not be happen.thats why error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d620d413-a4c1-48aa-9355-2df86cc63e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| name| age|experience|salary|\n",
      "+-----+----+----------+------+\n",
      "|  ram|  33|        12|  3000|\n",
      "|shyam|  43|        34|  7000|\n",
      "| jodu|  45|        56|  6000|\n",
      "|modhu|  65|        22|  8000|\n",
      "| hari|  77|         1|  9000|\n",
      "| mira|  56|        23| 10000|\n",
      "| valu|NULL|      NULL|  9030|\n",
      "| NULL|  45|         5| 67000|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##thresold\n",
    "df_pyspark.na.drop(how=\"any\",thresh=2).show() ## its means there need at least 2 non null value for not be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fff5c7eb-1d38-4833-8e28-6374fa0c645b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| name|age|experience|salary|\n",
      "+-----+---+----------+------+\n",
      "|  ram| 33|        12|  3000|\n",
      "|shyam| 43|        34|  7000|\n",
      "| jodu| 45|        56|  6000|\n",
      "|modhu| 65|        22|  8000|\n",
      "| hari| 77|         1|  9000|\n",
      "| mira| 56|        23| 10000|\n",
      "| NULL| 45|         5| 67000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##subset\n",
    "df_pyspark.na.drop(how=\"any\",subset=['Experience']).show() \n",
    "## whereever the experience have the null value it may deleted,\n",
    "##it subsettify the null to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bb9fc89f-76a7-4168-a991-7a7894fc23ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill the missing value\n",
    "df_pyspark=spark.read.csv('book3.csv',header=True,inferSchema=True)\n",
    "\n",
    "#df_pyspark.na.fill('missing value').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "43091d28-05fc-4d1e-b6fd-bbc07235fd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| name| age|experience|salary|\n",
      "+-----+----+----------+------+\n",
      "|  ram|  33|        12|  3000|\n",
      "|shyam|  43|        34|  7000|\n",
      "| jodu|  45|        56|  6000|\n",
      "|modhu|  65|        22|  8000|\n",
      "| hari|  77|         1|  9000|\n",
      "| mira|  56|        23| 10000|\n",
      "| valu|NULL|      NULL|  9030|\n",
      "| NULL|  45|         5| 67000|\n",
      "| NULL|  67|      NULL|  NULL|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('missing value',['experience','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "14e13b61-dec9-4390-ba99-c75d7fd234bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['age', 'experience', 'salary'], \n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'experience', 'salary']]\n",
    "    ).setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "faaeee92-98a3-43f9-b23d-c780b38b672c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ec9c2bdf-8836-4731-824f-2a53722bb51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "| name| age|experience|salary|age_imputed|experience_imputed|salary_imputed|\n",
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "|  ram|  33|        12|  3000|         33|                12|          3000|\n",
      "|shyam|  43|        34|  7000|         43|                34|          7000|\n",
      "| jodu|  45|        56|  6000|         45|                56|          6000|\n",
      "|modhu|  65|        22|  8000|         65|                22|          8000|\n",
      "| hari|  77|         1|  9000|         77|                 1|          9000|\n",
      "| mira|  56|        23| 10000|         56|                23|         10000|\n",
      "| valu|NULL|      NULL|  9030|         45|                22|          9030|\n",
      "| NULL|  45|         5| 67000|         45|                 5|         67000|\n",
      "| NULL|  67|      NULL|  NULL|         67|                22|          8000|\n",
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "175e6f8a-a1da-4008-952f-ec8a0ebcab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+------+\n",
      "|      Name|Age|Experiance|Salary|\n",
      "+----------+---+----------+------+\n",
      "|     krish| 31|        10| 30000|\n",
      "|sudhangshu| 30|         8| 25000|\n",
      "|     sunny| 29|         4| 20000|\n",
      "|      paul| 24|         3| 20000|\n",
      "|    Harsha| 21|         1| 15000|\n",
      "|    subham| 23|         2| 18000|\n",
      "+----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('book4.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9e58da69-2796-45e4-a3d0-2be851b4baff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experiance|Salary|\n",
      "+------+---+----------+------+\n",
      "| sunny| 29|         4| 20000|\n",
      "|  paul| 24|         3| 20000|\n",
      "|Harsha| 21|         1| 15000|\n",
      "|subham| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##filter operation\n",
    "##salary of the people less than or equal to 20000\n",
    "df_pyspark.filter(\"salary<=20000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0ed3fd78-bd6b-4f6c-a14f-b23686cfe070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "| sunny| 29|\n",
      "|  paul| 24|\n",
      "|Harsha| 21|\n",
      "|subham| 23|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"salary<=20000\").select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ef56b848-de07-4394-a57f-7da388d66d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experiance|Salary|\n",
      "+------+---+----------+------+\n",
      "| sunny| 29|         4| 20000|\n",
      "|  paul| 24|         3| 20000|\n",
      "|Harsha| 21|         1| 15000|\n",
      "|subham| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for multiple condition\n",
    "df_pyspark.filter((df_pyspark['salary']<=20000) & (df_pyspark['salary']>=15000)).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "33446322-f7e4-4c60-b5e5-075e5b7b86ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+------+\n",
      "|      Name|Age|Experiance|Salary|\n",
      "+----------+---+----------+------+\n",
      "|     krish| 31|        10| 30000|\n",
      "|sudhangshu| 30|         8| 25000|\n",
      "|     sunny| 29|         4| 20000|\n",
      "|      paul| 24|         3| 20000|\n",
      "|    Harsha| 21|         1| 15000|\n",
      "|    subham| 23|         2| 18000|\n",
      "+----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['salary']<=20000)|(df_pyspark['salary']>=15000)).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3217a7c2-1ccf-449a-a0f5-69e906d2518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+------+\n",
      "|      Name|Age|Experiance|Salary|\n",
      "+----------+---+----------+------+\n",
      "|     krish| 31|        10| 30000|\n",
      "|sudhangshu| 30|         8| 25000|\n",
      "+----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['salary']<=20000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "86f96130-46eb-4afb-a858-c875c91ccf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2d3f1fe1-8b35-42bf-924c-7ee31f3465db",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Agg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "06150ef8-d3bb-448c-a6bb-b819ea485ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-I1UD8IKQ:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x24cdb9408f0>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "76cef7af-faf7-4e00-8dee-c6789059e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('book5.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a5ac8247-0c0f-48b1-b141-b8b0d7a0fc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|    krish|Data Science| 10000|\n",
      "|    krish|         IOT|  5000|\n",
      "|   mahesh|    Big Data|  4000|\n",
      "|    krish|    Big Data|  4000|\n",
      "|   mahesh|Data Science|  3000|\n",
      "|sudhanshu|Data Science| 20000|\n",
      "|sudhanshu|         IOT| 10000|\n",
      "|sudhanshu|    Big Data|  5000|\n",
      "|    sunny|Data Science| 10000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b75a30d1-f7fc-4d19-ae39-d35afdbecf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Departments: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8dcd00f5-8cb7-4bbd-a123-3729828ce088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|sum(salary)|\n",
      "+---------+-----------+\n",
      "|    sunny|      10000|\n",
      "|    krish|      19000|\n",
      "|sudhanshu|      35000|\n",
      "|   mahesh|       7000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##groupby\n",
    "df_pyspark.groupBy('Name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "363f6d2a-076c-43b9-b4e1-2305cbcf9065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|sum(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      15000|\n",
      "|    Big Data|      13000|\n",
      "|Data Science|      43000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "36bcb11b-f901-41ce-a83f-e681ca31af18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|min(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|       5000|\n",
      "|    Big Data|       4000|\n",
      "|Data Science|       3000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').min().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0692a6b8-0d92-4193-a1c2-caa720344d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| Departments|count|\n",
      "+------------+-----+\n",
      "|         IOT|    2|\n",
      "|    Big Data|    3|\n",
      "|Data Science|    4|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "035ef82c-3c61-4a7b-8f6e-f9b4dfc44687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|      71000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'Sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c2244206-6369-4774-9d0f-ca868188cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = spark.read.csv('Book4.csv',header = True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7f9cc9f3-0fb0-40e8-800d-da935a945dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+------+\n",
      "|      Name|Age|Experiance|Salary|\n",
      "+----------+---+----------+------+\n",
      "|     krish| 31|        10| 30000|\n",
      "|sudhangshu| 30|         8| 25000|\n",
      "|     sunny| 29|         4| 20000|\n",
      "|      paul| 24|         3| 20000|\n",
      "|    Harsha| 21|         1| 15000|\n",
      "|    subham| 23|         2| 18000|\n",
      "+----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e6520481-5910-4e62-9bd5-411187efcae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experiance: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e4a59274-07c1-449f-8aad-391d40af5e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experiance', 'Salary']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "68fc5167-ba2b-479e-8df7-356c75377dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=[\"Age\",\"Experiance\"],outputCol=\"Independent features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "426326cf-2722-4161-b8ac-a96f15e7621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=featureassembler.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6974e970-3674-432c-ae28-353d077b16f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+------+--------------------+\n",
      "|      Name|Age|Experiance|Salary|Independent features|\n",
      "+----------+---+----------+------+--------------------+\n",
      "|     krish| 31|        10| 30000|         [31.0,10.0]|\n",
      "|sudhangshu| 30|         8| 25000|          [30.0,8.0]|\n",
      "|     sunny| 29|         4| 20000|          [29.0,4.0]|\n",
      "|      paul| 24|         3| 20000|          [24.0,3.0]|\n",
      "|    Harsha| 21|         1| 15000|          [21.0,1.0]|\n",
      "|    subham| 23|         2| 18000|          [23.0,2.0]|\n",
      "+----------+---+----------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "852f3f29-2c2c-47a9-b023-40557a00ddfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experiance', 'Salary', 'Independent features']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "89d79efa-ebdd-4b9d-aa7a-3a0ed19f7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalize_data=output.select(\"independent Features\",\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1748e285-5bb3-4c93-8497-fbff3a095428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|independent Features|salary|\n",
      "+--------------------+------+\n",
      "|         [31.0,10.0]| 30000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "|          [29.0,4.0]| 20000|\n",
      "|          [24.0,3.0]| 20000|\n",
      "|          [21.0,1.0]| 15000|\n",
      "|          [23.0,2.0]| 18000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalize_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "791c15f9-c875-47c3-9d89-979b8fce5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "##train test split\n",
    "train_data,test_data=finalize_data.randomSplit([0.75,0.25])\n",
    "regressor=LinearRegression(featuresCol='independent Features', labelCol='salary')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "bceb883b-390c-47a0-9932-a325d4489f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-714.2857, 3485.7143])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Coefficients\n",
    "regressor.coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "60c8566b-929c-44ba-9370-6a97009bbed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26857.142857139796"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Intercepts\n",
    "regressor.intercept\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4c3382e6-fb3a-48af-99d1-d12354df7a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------------+\n",
      "|independent Features|salary|       prediction|\n",
      "+--------------------+------+-----------------+\n",
      "|          [30.0,8.0]| 25000|33314.28571428435|\n",
      "|         [31.0,10.0]| 30000|39571.42857142653|\n",
      "+--------------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Prediction\n",
    "pred_results=regressor.evaluate(test_data)\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8189d4b-6d8d-4ff1-a68b-5388e962d457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
